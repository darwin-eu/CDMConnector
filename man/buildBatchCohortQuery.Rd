% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimizer.R
\name{buildBatchCohortQuery}
\alias{buildBatchCohortQuery}
\title{Build optimized batch cohort SQL using the execution DAG}
\usage{
buildBatchCohortQuery(
  cohort_list,
  cohort_ids,
  options = list(),
  cache = FALSE,
  con = NULL,
  schema = NULL
)
}
\arguments{
\item{cohort_list}{List of cohort expression lists (from cohortExpressionFromJson).}

\item{cohort_ids}{Integer vector, same length as cohort_list.}

\item{options}{List with cdm_schema, vocabulary_schema, results_schema, table_prefix.}

\item{cache}{Logical; if TRUE, enable incremental caching (default FALSE).}

\item{con}{DBI connection; required when \code{cache = TRUE}.}

\item{schema}{Character resolved schema name; required when \code{cache = TRUE}.}
}
\value{
When \code{cache = FALSE}: single SQL string.
When \code{cache = TRUE}: list with \code{sql}, \code{dag}, \code{cache_hits}, \code{cache_misses}.
}
\description{
Builds an execution graph (DAG) from cohort definitions, deduplicates shared
computation nodes, and emits a single SQL script with schema-qualified
prefixed working tables (no temp tables).
}
\details{
When \code{cache = TRUE} and a DBI connection is provided, the function
checks a persistent cache registry for previously computed nodes.  Nodes
whose content hash already exists in the cache are skipped, and only new
or changed nodes are materialized.
}
\keyword{internal}
